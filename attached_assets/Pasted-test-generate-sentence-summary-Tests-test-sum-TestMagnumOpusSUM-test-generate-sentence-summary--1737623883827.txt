test_generate_sentence_summary (Tests.test_sum.TestMagnumOpusSUM.test_generate_sentence_summary) ... /home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/httpx/_config.py:156: DeprecationWarning: ssl.PROTOCOL_TLS is deprecated
  context = ssl.SSLContext(ssl.PROTOCOL_TLS)
/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/httpx/_config.py:159: DeprecationWarning: ssl.OP_NO_SSL*/ssl.OP_NO_TLS* options are deprecated
  context.options |= ssl.OP_NO_TLSv1
/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/httpx/_config.py:160: DeprecationWarning: ssl.OP_NO_SSL*/ssl.OP_NO_TLS* options are deprecated
  context.options |= ssl.OP_NO_TLSv1_1
ERROR
test_generate_tag_summary (Tests.test_sum.TestMagnumOpusSUM.test_generate_tag_summary) ... ERROR
test_preprocess_text (Tests.test_sum.TestMagnumOpusSUM.test_preprocess_text) ... ERROR
test_adjust_parameters (Tests.test_sum.TestSUM.test_adjust_parameters) ... ok
test_detect_language (Tests.test_sum.TestSUM.test_detect_language) ... ok
test_extract_keywords (Tests.test_sum.TestSUM.test_extract_keywords) ... ok
test_generate_summaries (Tests.test_sum.TestSUM.test_generate_summaries) ... ERROR
test_generate_word_cloud (Tests.test_sum.TestSUM.test_generate_word_cloud) ... ok
test_identify_entities (Tests.test_sum.TestSUM.test_identify_entities) ... ok
test_identify_main_concept (Tests.test_sum.TestSUM.test_identify_main_concept) ... ok
test_preprocess_text (Tests.test_sum.TestSUM.test_preprocess_text) ... ERROR
test_sentiment_analysis (Tests.test_sum.TestSUM.test_sentiment_analysis) ... ok
test_translate_text (Tests.test_sum.TestSUM.test_translate_text) ... ok
/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/lib/python3.12/unittest/suite.py:84: ResourceWarning: unclosed <ssl.SSLSocket fd=4, family=2, type=1, proto=6, laddr=('172.31.196.31', 34762), raddr=('74.125.132.95', 443)>
  return self.run(*args, **kwds)
ResourceWarning: Enable tracemalloc to get the object allocation traceback

======================================================================
ERROR: test_generate_sentence_summary (Tests.test_sum.TestMagnumOpusSUM.test_generate_sentence_summary)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/runner/workspace/Tests/test_sum.py", line 88, in test_generate_sentence_summary
    summary = self.summarizer.generate_sentence_summary(self.test_text)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/SUM.py", line 78, in generate_sentence_summary
    sentences = sent_tokenize(text)
                ^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource punkt_tab not found.
  Please use the NLTK Downloader to obtain the resource:

  >>> import nltk
  >>> nltk.download('punkt_tab')
  
  For more information see: https://www.nltk.org/data.html

  Attempted to load tokenizers/punkt_tab/english/

  Searched in:
    - '/home/runner/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/share/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************


======================================================================
ERROR: test_generate_tag_summary (Tests.test_sum.TestMagnumOpusSUM.test_generate_tag_summary)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/runner/workspace/Tests/test_sum.py", line 83, in test_generate_tag_summary
    tags = self.summarizer.generate_tag_summary(self.test_text)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/SUM.py", line 73, in generate_tag_summary
    words = word_tokenize(text.lower())
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource punkt_tab not found.
  Please use the NLTK Downloader to obtain the resource:

  >>> import nltk
  >>> nltk.download('punkt_tab')
  
  For more information see: https://www.nltk.org/data.html

  Attempted to load tokenizers/punkt_tab/english/

  Searched in:
    - '/home/runner/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/share/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************


======================================================================
ERROR: test_preprocess_text (Tests.test_sum.TestMagnumOpusSUM.test_preprocess_text)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/runner/workspace/Tests/test_sum.py", line 78, in test_preprocess_text
    processed = self.summarizer.preprocess_text(self.test_text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/SUM.py", line 69, in preprocess_text
    words = word_tokenize(text.lower())
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource punkt_tab not found.
  Please use the NLTK Downloader to obtain the resource:

  >>> import nltk
  >>> nltk.download('punkt_tab')
  
  For more information see: https://www.nltk.org/data.html

  Attempted to load tokenizers/punkt_tab/english/

  Searched in:
    - '/home/runner/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/share/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************


======================================================================
ERROR: test_generate_summaries (Tests.test_sum.TestSUM.test_generate_summaries)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/runner/workspace/Tests/test_sum.py", line 27, in test_generate_summaries
    summaries = self.summarizer.generate_summaries([self.test_text])
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'MagnumOpusSUM' object has no attribute 'generate_summaries'

======================================================================
ERROR: test_preprocess_text (Tests.test_sum.TestSUM.test_preprocess_text)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/runner/workspace/Tests/test_sum.py", line 21, in test_preprocess_text
    preprocessed = self.summarizer.preprocess_text(self.test_text)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/SUM.py", line 69, in preprocess_text
    words = word_tokenize(text.lower())
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource punkt_tab not found.
  Please use the NLTK Downloader to obtain the resource:

  >>> import nltk
  >>> nltk.download('punkt_tab')
  
  For more information see: https://www.nltk.org/data.html

  Attempted to load tokenizers/punkt_tab/english/

  Searched in:
    - '/home/runner/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/share/nltk_data'
    - '/nix/store/nb21sc3npfc8gvazwnrjxpvb5d48jysx-python3-3.12.7/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************


----------------------------------------------------------------------
Ran 13 tests in 7.564s

FAILED (errors=5)