# SUM: Knowledge Crystallization System

<div align="center">

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://python.org)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)]()
[![API](https://img.shields.io/badge/API-REST-orange.svg)](docs/API_DOCUMENTATION.md)

**Transform information into crystallized knowledge through intelligent summarization, semantic memory, and cross-document synthesis.**

[Features](#features) â€¢ [Quick Start](#quick-start) â€¢ [API Documentation](docs/API_DOCUMENTATION.md) â€¢ [Architecture](#architecture) â€¢ [Performance](#performance)

</div>

## ğŸ¯ Overview

SUM is an advanced knowledge management system that goes beyond simple text summarization. It provides intelligent document processing with semantic understanding, knowledge persistence, and the ability to synthesize insights across multiple documents.

### Key Capabilities

- **ğŸ§  Intelligent Summarization** - Multi-density summaries from tags to comprehensive analysis
- **ğŸ’¾ Semantic Memory** - Vector-based storage for intelligent retrieval and knowledge persistence
- **ğŸ”— Knowledge Synthesis** - Cross-document analysis with contradiction detection and consensus building
- **ğŸ“Š Real-time Processing** - Stream-based architecture for handling large documents
- **ğŸ”„ Feedback Learning** - Adaptive system that improves based on user preferences
- **ğŸ“ˆ Production Ready** - Comprehensive monitoring, health checks, and error recovery

## âœ¨ Features

### Core Summarization Engine
- **Multi-Density Output**
  - `tags`: Key terms and entities extraction
  - `minimal`: One-sentence summary
  - `short`: Three-sentence overview
  - `medium`: Five-sentence summary
  - `detailed`: Comprehensive analysis
- **Universal File Support** - Process ANY file type with intelligent text extraction
- **Streaming Architecture** - Handle documents of any size with progress tracking
- **Memory-Optimized** - Chunked processing for files up to 100MB+

### Knowledge Management
- **Semantic Memory Storage**
  - Vector embeddings for similarity search
  - Multiple backend support (ChromaDB, FAISS, NumPy)
  - Persistent storage with automatic loading
- **Knowledge Graph Integration**
  - Entity and relationship extraction
  - Graph-based knowledge representation
  - Path finding between concepts
- **Cross-Document Synthesis**
  - Intelligent document merging
  - Contradiction detection
  - Consensus identification
  - Concept evolution tracking

### Production Features
- **ğŸ›¡ï¸ Comprehensive Error Handling**
  - Custom exception hierarchy
  - Graceful degradation
  - Detailed error tracking
- **âš™ï¸ Configuration Management**
  - Environment-based configs
  - Validation with type checking
  - Secure production defaults
- **ğŸ“Š Monitoring & Health**
  - Health check endpoints
  - Prometheus metrics
  - Resource usage tracking
  - Component status monitoring
- **ğŸš€ Performance Optimization**
  - Multi-layer caching (memory + disk)
  - Asynchronous processing pipeline
  - Connection pooling ready
- **ğŸ“š Developer Experience**
  - Comprehensive API documentation
  - SDK examples
  - OpenAPI specification

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- 4GB RAM minimum (8GB recommended)
- 1GB free disk space

### Installation

```bash
# Clone the repository
git clone https://github.com/OtotaO/SUM.git
cd SUM

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download language models
python -m spacy download en_core_web_sm

# Initialize knowledge systems
python setup_knowledge.py
```

### Basic Usage

```bash
# Start the server
python main.py

# The web interface will be available at http://localhost:3000
```

### API Example

```python
import requests

# Summarize text
response = requests.post('http://localhost:3000/api/summarize', 
    json={
        'text': 'Your long text here...',
        'density': 'medium'
    })

summary = response.json()['summary']
```

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              User Interface Layer                â”‚
â”‚         (Web UI, REST API, Streaming)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚            Knowledge Processing Layer            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Summarizer  â”‚ â”‚   Semantic   â”‚ â”‚ Knowledgeâ”‚ â”‚
â”‚  â”‚   Engine    â”‚ â”‚    Memory    â”‚ â”‚   Graph  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Async Processing Pipeline                â”‚
â”‚  - Concurrent processing                         â”‚
â”‚  - Stream-based handling                         â”‚
â”‚  - Progress tracking                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Storage & Persistence Layer                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Cache   â”‚ â”‚   Vector   â”‚ â”‚   Metadata    â”‚ â”‚
â”‚  â”‚  Layer   â”‚ â”‚   Store    â”‚ â”‚   Storage     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

- **Core**: Python 3.8+, Flask
- **ML/NLP**: Transformers, Sentence-Transformers, spaCy
- **Storage**: ChromaDB/FAISS for vectors, JSON for metadata
- **Processing**: AsyncIO, ThreadPoolExecutor
- **Monitoring**: Prometheus-compatible metrics

## ğŸ“ˆ Performance

### Benchmarks

| Operation | Small (<1MB) | Medium (1-10MB) | Large (10-100MB) |
|-----------|--------------|-----------------|------------------|
| Summarization | <1s | 2-5s | 10-30s |
| Semantic Search | <100ms | <100ms | <100ms |
| Document Synthesis | <2s | 5-10s | 20-60s |

### Optimization Features

- **Embedding Cache**: ~80% reduction in generation time for cached content
- **Chunked Processing**: Handles files up to 100MB without memory issues
- **Async Pipeline**: 10x faster batch processing
- **Smart Fallbacks**: Graceful degradation when components unavailable

## ğŸ”’ Security & Reliability

- **Input Validation**: Comprehensive validation for all inputs
- **Error Recovery**: Automatic retry with exponential backoff
- **Rate Limiting**: Configurable per-endpoint limits
- **Health Monitoring**: Kubernetes-ready health probes
- **Secure Defaults**: Production-ready configuration

## ğŸ“š Documentation

- [API Documentation](docs/API_DOCUMENTATION.md) - Complete endpoint reference
- [Configuration Guide](docs/CONFIGURATION.md) - Setup and customization
- [Architecture Overview](docs/ARCHITECTURE.md) - System design details
- [Deployment Guide](docs/DEPLOYMENT.md) - Production deployment

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
pytest

# Run linters
flake8 .
black .
```

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with [Hugging Face Transformers](https://huggingface.co/transformers/)
- Vector storage powered by [ChromaDB](https://www.trychroma.com/) and [FAISS](https://github.com/facebookresearch/faiss)
- NLP capabilities from [spaCy](https://spacy.io/)

---

<div align="center">

**Built with â¤ï¸ for the knowledge worker of tomorrow**

[Report Bug](https://github.com/OtotaO/SUM/issues) â€¢ [Request Feature](https://github.com/OtotaO/SUM/issues)

</div>